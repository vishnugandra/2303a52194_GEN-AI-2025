{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT-1\n",
        "2303A52194"
      ],
      "metadata": {
        "id": "e0qrCmpoidkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries\n",
        "YActual YP red\n",
        "20 20.5\n",
        "30 30.3\n",
        "40 40.2\n",
        "50 50.6\n",
        "60 60.7\n",
        "Tabela 1: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "k00DCE2snqxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mse = sum((y_true[i] - y_pred[i]) ** 2 for i in range(n)) / n\n",
        "    return mse\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mae = sum(abs(y_true[i] - y_pred[i]) for i in range(n)) / n\n",
        "    return mae\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    return rmse\n",
        "\n",
        "\n",
        "y_true = [20,30,40,50,60]\n",
        "y_pred = [20.5,30.3,40.2,50.6,60.7]\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_true, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqQWQ5Ghm0sv",
        "outputId": "6d183eb5-d00f-4f7a-d241-215c7133cd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.24600000000000147\n",
            "MAE: 0.4600000000000016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpjM8fOzhWqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b414e6d9-1523-47d0-8879-13d9330a2467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n"
          ]
        }
      ],
      "source": [
        "YActual = [20, 30, 40, 50, 60]\n",
        "YPred = [20.5, 30.3, 40.2, 50.6, 60.7]\n",
        "\n",
        "mae = sum(abs(ya - yp) for ya, yp in zip(YActual, YPred)) / len(YActual)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "\n",
        "mse = sum((ya - yp) ** 2 for ya, yp in zip(YActual, YPred)) / len(YActual)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "mae_lib = mean_absolute_error(YActual, YPred)\n",
        "mse_lib = mean_squared_error(YActual, YPred)\n",
        "print(f\"Library Mean Absolute Error (MAE): {mae_lib}\")\n",
        "print(f\"Library Mean Squared Error (MSE): {mse_lib}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLxe5Z7pmcK2",
        "outputId": "5fd773dd-972b-4f9a-ebf4-687c7b33ebf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Library Mean Squared Error (MSE): 0.24600000000000147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YActual2 = [\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 1],\n",
        "    [2, 2, 1, 1],\n",
        "    [2, 0, 1, 1],\n",
        "    [2, 2, 2, 2]\n",
        "]\n",
        "YPred2 = [\n",
        "    [1, 1, 2, 0],\n",
        "    [1, 0, 2, 0],\n",
        "    [1, 2, 2, 1],\n",
        "    [1, 0, 2, 2],\n",
        "    [1, 2, 2, 2]\n",
        "]\n",
        "\n",
        "YActual2_flat = []\n",
        "for sublist in YActual2:\n",
        "    for item in sublist:\n",
        "        YActual2_flat.append(item)\n",
        "\n",
        "YPred2_flat = []\n",
        "for sublist in YPred2:\n",
        "    for item in sublist:\n",
        "        YPred2_flat.append(item)\n",
        "\n",
        "correct_predictions = 0\n",
        "for i in range(len(YActual2_flat)):\n",
        "    if YActual2_flat[i] == YPred2_flat[i]:\n",
        "        correct_predictions += 1\n",
        "accuracy = correct_predictions / len(YActual2_flat)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "true_positive = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "\n",
        "for i in range(len(YActual2_flat)):\n",
        "    if YActual2_flat[i] == 1 and YPred2_flat[i] == 1:\n",
        "        true_positive += 1\n",
        "    if YActual2_flat[i] != 1 and YPred2_flat[i] == 1:\n",
        "        false_positive += 1\n",
        "    if YActual2_flat[i] == 1 and YPred2_flat[i] != 1:\n",
        "        false_negative += 1\n",
        "\n",
        "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
        "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "mBQRlFDyqHE-",
        "outputId": "eb176fc8-05da-4e55-c965-da52b7b8eb0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4\n",
            "Precision: 0.14285714285714285\n",
            "Recall: 0.2\n",
            "F1-Score: 0.16666666666666666\n"
          ]
        }
      ]
    }
  ]
}